<!DOCTYPE html><html><head><meta charset="utf-8"><style>body {
  max-width: 980px;
  border: 1px solid #ddd;
  outline: 1300px solid #fff;
  margin: 16px auto;
}

body .markdown-body
{
  padding: 45px;
}

@font-face {
  font-family: fontawesome-mini;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

@font-face {
  font-family: octicons-anchor;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

.markdown-body {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  color: #333333;
  overflow: hidden;
  font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif;
  font-size: 16px;
  line-height: 1.6;
  word-wrap: break-word;
}

.markdown-body a {
  background: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline: 0;
}

.markdown-body b,
.markdown-body strong {
  font-weight: bold;
}

.markdown-body mark {
  background: #ff0;
  color: #000;
  font-style: italic;
  font-weight: bold;
}

.markdown-body sub,
.markdown-body sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
.markdown-body sup {
  top: -0.5em;
}
.markdown-body sub {
  bottom: -0.25em;
}

.markdown-body h1 {
  font-size: 2em;
  margin: 0.67em 0;
}

.markdown-body img {
  border: 0;
}

.markdown-body hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}

.markdown-body pre {
  overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre,
.markdown-body samp {
  font-family: monospace, monospace;
  font-size: 1em;
}

.markdown-body input {
  color: inherit;
  font: inherit;
  margin: 0;
}

.markdown-body html input[disabled] {
  cursor: default;
}

.markdown-body input {
  line-height: normal;
}

.markdown-body input[type="checkbox"] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body .codehilitetable {
  border: 0;
  border-spacing: 0;
}

.markdown-body .codehilitetable tr {
  border: 0;
}

.markdown-body .codehilitetable pre,
.markdown-body .codehilitetable div.codehilite {
  margin: 0;
}

.markdown-body .linenos,
.markdown-body .code,
.markdown-body .codehilitetable td {
  border: 0;
  padding: 0;
}

.markdown-body td:not(.linenos) .linenodiv {
  padding: 0 !important;
}

.markdown-body .code {
  width: 100%;
}

.markdown-body .linenos div pre,
.markdown-body .linenodiv pre,
.markdown-body .linenodiv {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-left-radius: 3px;
  -webkit-border-bottom-left-radius: 3px;
  -moz-border-radius-topleft: 3px;
  -moz-border-radius-bottomleft: 3px;
  border-top-left-radius: 3px;
  border-bottom-left-radius: 3px;
}

.markdown-body .code div pre,
.markdown-body .code div {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-right-radius: 3px;
  -webkit-border-bottom-right-radius: 3px;
  -moz-border-radius-topright: 3px;
  -moz-border-radius-bottomright: 3px;
  border-top-right-radius: 3px;
  border-bottom-right-radius: 3px;
}

.markdown-body * {
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body input {
  font: 13px Helvetica, arial, freesans, clean, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol";
  line-height: 1.4;
}

.markdown-body a {
  color: #4183c4;
  text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:focus,
.markdown-body a:active {
  text-decoration: underline;
}

.markdown-body hr {
  height: 0;
  margin: 15px 0;
  overflow: hidden;
  background: transparent;
  border: 0;
  border-bottom: 1px solid #ddd;
}

.markdown-body hr:before,
.markdown-body hr:after {
  display: table;
  content: " ";
}

.markdown-body hr:after {
  clear: both;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 15px;
  margin-bottom: 15px;
  line-height: 1.1;
}

.markdown-body h1 {
  font-size: 30px;
}

.markdown-body h2 {
  font-size: 21px;
}

.markdown-body h3 {
  font-size: 16px;
}

.markdown-body h4 {
  font-size: 14px;
}

.markdown-body h5 {
  font-size: 12px;
}

.markdown-body h6 {
  font-size: 11px;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ul,
.markdown-body ol {
  padding: 0;
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre,
.markdown-body samp {
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body kbd {
  background-color: #e7e7e7;
  background-image: -moz-linear-gradient(#fefefe, #e7e7e7);
  background-image: -webkit-linear-gradient(#fefefe, #e7e7e7);
  background-image: linear-gradient(#fefefe, #e7e7e7);
  background-repeat: repeat-x;
  border-radius: 2px;
  border: 1px solid #cfcfcf;
  color: #000;
  padding: 3px 5px;
  line-height: 10px;
  font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
  display: inline-block;
}

.markdown-body>*:first-child {
  margin-top: 0 !important;
}

.markdown-body>*:last-child {
  margin-bottom: 0 !important;
}

.markdown-body .headeranchor-link {
  position: absolute;
  top: 0;
  bottom: 0;
  left: 0;
  display: block;
  padding-right: 6px;
  padding-left: 30px;
  margin-left: -30px;
}

.markdown-body .headeranchor-link:focus {
  outline: none;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  position: relative;
  margin-top: 1em;
  margin-bottom: 16px;
  font-weight: bold;
  line-height: 1.4;
}

.markdown-body h1 .headeranchor,
.markdown-body h2 .headeranchor,
.markdown-body h3 .headeranchor,
.markdown-body h4 .headeranchor,
.markdown-body h5 .headeranchor,
.markdown-body h6 .headeranchor {
  display: none;
  color: #000;
  vertical-align: middle;
}

.markdown-body h1:hover .headeranchor-link,
.markdown-body h2:hover .headeranchor-link,
.markdown-body h3:hover .headeranchor-link,
.markdown-body h4:hover .headeranchor-link,
.markdown-body h5:hover .headeranchor-link,
.markdown-body h6:hover .headeranchor-link {
  height: 1em;
  padding-left: 8px;
  margin-left: -30px;
  line-height: 1;
  text-decoration: none;
}

.markdown-body h1:hover .headeranchor-link .headeranchor,
.markdown-body h2:hover .headeranchor-link .headeranchor,
.markdown-body h3:hover .headeranchor-link .headeranchor,
.markdown-body h4:hover .headeranchor-link .headeranchor,
.markdown-body h5:hover .headeranchor-link .headeranchor,
.markdown-body h6:hover .headeranchor-link .headeranchor {
  display: inline-block;
}

.markdown-body h1 {
  padding-bottom: 0.3em;
  font-size: 2.25em;
  line-height: 1.2;
  border-bottom: 1px solid #eee;
}

.markdown-body h2 {
  padding-bottom: 0.3em;
  font-size: 1.75em;
  line-height: 1.225;
  border-bottom: 1px solid #eee;
}

.markdown-body h3 {
  font-size: 1.5em;
  line-height: 1.43;
}

.markdown-body h4 {
  font-size: 1.25em;
}

.markdown-body h5 {
  font-size: 1em;
}

.markdown-body h6 {
  font-size: 1em;
  color: #777;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre,
.markdown-body .admonition {
  margin-top: 0;
  margin-bottom: 16px;
}

.markdown-body hr {
  height: 4px;
  padding: 0;
  margin: 16px 0;
  background-color: #e7e7e7;
  border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
  padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: bold;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body blockquote {
  padding: 0 15px;
  color: #777;
  border-left: 4px solid #ddd;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body table {
  display: block;
  width: 100%;
  overflow: auto;
  word-break: normal;
  word-break: keep-all;
}

.markdown-body table th {
  font-weight: bold;
}

.markdown-body table th,
.markdown-body table td {
  padding: 6px 13px;
  border: 1px solid #ddd;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

.markdown-body img {
  max-width: 100%;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body code,
.markdown-body samp {
  padding: 0;
  padding-top: 0.2em;
  padding-bottom: 0.2em;
  margin: 0;
  font-size: 85%;
  background-color: rgba(0,0,0,0.04);
  border-radius: 3px;
}

.markdown-body code:before,
.markdown-body code:after {
  letter-spacing: -0.2em;
  content: "\00a0";
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
  font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .codehilite {
  margin-bottom: 16px;
}

.markdown-body .codehilite pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  background-color: #f7f7f7;
  border-radius: 3px;
}

.markdown-body .codehilite pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre code {
  display: inline;
  max-width: initial;
  padding: 0;
  margin: 0;
  overflow: initial;
  line-height: inherit;
  word-wrap: normal;
  background-color: transparent;
  border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
  content: normal;
}

/* Admonition */
.markdown-body .admonition {
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  position: relative;
  border-radius: 3px;
  border: 1px solid #e0e0e0;
  border-left: 6px solid #333;
  padding: 10px 10px 10px 30px;
}

.markdown-body .admonition table {
  color: #333;
}

.markdown-body .admonition p {
  padding: 0;
}

.markdown-body .admonition-title {
  font-weight: bold;
  margin: 0;
}

.markdown-body .admonition>.admonition-title {
  color: #333;
}

.markdown-body .attention>.admonition-title {
  color: #a6d796;
}

.markdown-body .caution>.admonition-title {
  color: #d7a796;
}

.markdown-body .hint>.admonition-title {
  color: #96c6d7;
}

.markdown-body .danger>.admonition-title {
  color: #c25f77;
}

.markdown-body .question>.admonition-title {
  color: #96a6d7;
}

.markdown-body .note>.admonition-title {
  color: #d7c896;
}

.markdown-body .admonition:before,
.markdown-body .attention:before,
.markdown-body .caution:before,
.markdown-body .hint:before,
.markdown-body .danger:before,
.markdown-body .question:before,
.markdown-body .note:before {
  font: normal normal 16px fontawesome-mini;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  line-height: 1.5;
  color: #333;
  position: absolute;
  left: 0;
  top: 0;
  padding-top: 10px;
  padding-left: 10px;
}

.markdown-body .admonition:before {
  content: "\f056\00a0";
  color: 333;
}

.markdown-body .attention:before {
  content: "\f058\00a0";
  color: #a6d796;
}

.markdown-body .caution:before {
  content: "\f06a\00a0";
  color: #d7a796;
}

.markdown-body .hint:before {
  content: "\f05a\00a0";
  color: #96c6d7;
}

.markdown-body .danger:before {
  content: "\f057\00a0";
  color: #c25f77;
}

.markdown-body .question:before {
  content: "\f059\00a0";
  color: #96a6d7;
}

.markdown-body .note:before {
  content: "\f040\00a0";
  color: #d7c896;
}

.markdown-body .admonition::after {
  content: normal;
}

.markdown-body .attention {
  border-left: 6px solid #a6d796;
}

.markdown-body .caution {
  border-left: 6px solid #d7a796;
}

.markdown-body .hint {
  border-left: 6px solid #96c6d7;
}

.markdown-body .danger {
  border-left: 6px solid #c25f77;
}

.markdown-body .question {
  border-left: 6px solid #96a6d7;
}

.markdown-body .note {
  border-left: 6px solid #d7c896;
}

.markdown-body .admonition>*:first-child {
  margin-top: 0 !important;
}

.markdown-body .admonition>*:last-child {
  margin-bottom: 0 !important;
}

/* progress bar*/
.markdown-body .progress {
  display: block;
  width: 300px;
  margin: 10px 0;
  height: 24px;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #ededed;
  position: relative;
  box-shadow: inset -1px 1px 3px rgba(0, 0, 0, .1);
}

.markdown-body .progress-label {
  position: absolute;
  text-align: center;
  font-weight: bold;
  width: 100%; margin: 0;
  line-height: 24px;
  color: #333;
  text-shadow: 1px 1px 0 #fefefe, -1px -1px 0 #fefefe, -1px 1px 0 #fefefe, 1px -1px 0 #fefefe, 0 1px 0 #fefefe, 0 -1px 0 #fefefe, 1px 0 0 #fefefe, -1px 0 0 #fefefe, 1px 1px 2px #000;
  -webkit-font-smoothing: antialiased !important;
  white-space: nowrap;
  overflow: hidden;
}

.markdown-body .progress-bar {
  height: 24px;
  float: left;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #96c6d7;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, .5), inset 0 -1px 0 rgba(0, 0, 0, .1);
  background-size: 30px 30px;
  background-image: -webkit-linear-gradient(
    135deg, rgba(255, 255, 255, .4) 27%,
    transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%,
    transparent 77%, transparent
  );
  background-image: -moz-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -ms-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -o-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
}

.markdown-body .progress-100plus .progress-bar {
  background-color: #a6d796;
}

.markdown-body .progress-80plus .progress-bar {
  background-color: #c6d796;
}

.markdown-body .progress-60plus .progress-bar {
  background-color: #d7c896;
}

.markdown-body .progress-40plus .progress-bar {
  background-color: #d7a796;
}

.markdown-body .progress-20plus .progress-bar {
  background-color: #d796a6;
}

.markdown-body .progress-0plus .progress-bar {
  background-color: #c25f77;
}

.markdown-body .candystripe-animate .progress-bar{
  -webkit-animation: animate-stripes 3s linear infinite;
  -moz-animation: animate-stripes 3s linear infinite;
  animation: animate-stripes 3s linear infinite;
}

@-webkit-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@-moz-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

.markdown-body .gloss .progress-bar {
  box-shadow:
    inset 0 4px 12px rgba(255, 255, 255, .7),
    inset 0 -12px 0 rgba(0, 0, 0, .05);
}

/* Multimarkdown Critic Blocks */
.markdown-body .critic_mark {
  background: #ff0;
}

.markdown-body .critic_delete {
  color: #c82829;
  text-decoration: line-through;
}

.markdown-body .critic_insert {
  color: #718c00 ;
  text-decoration: underline;
}

.markdown-body .critic_comment {
  color: #8e908c;
  font-style: italic;
}

.markdown-body .headeranchor {
  font: normal normal 16px octicons-anchor;
  line-height: 1;
  display: inline-block;
  text-decoration: none;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.headeranchor:before {
  content: '\f05c';
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 4px 0.25em -20px;
  vertical-align: middle;
}

/* Media */
@media only screen and (min-width: 480px) {
  .markdown-body {
    font-size:14px;
  }
}

@media only screen and (min-width: 768px) {
  .markdown-body {
    font-size:16px;
  }
}

@media print {
  .markdown-body * {
    background: transparent !important;
    color: black !important;
    filter:none !important;
    -ms-filter: none !important;
  }

  .markdown-body {
    font-size:12pt;
    max-width:100%;
    outline:none;
    border: 0;
  }

  .markdown-body a,
  .markdown-body a:visited {
    text-decoration: underline;
  }

  .markdown-body .headeranchor-link {
    display: none;
  }

  .markdown-body a[href]:after {
    content: " (" attr(href) ")";
  }

  .markdown-body abbr[title]:after {
    content: " (" attr(title) ")";
  }

  .markdown-body .ir a:after,
  .markdown-body a[href^="javascript:"]:after,
  .markdown-body a[href^="#"]:after {
    content: "";
  }

  .markdown-body pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .markdown-body pre,
  .markdown-body blockquote {
    border: 1px solid #999;
    padding-right: 1em;
    page-break-inside: avoid;
  }

  .markdown-body .progress,
  .markdown-body .progress-bar {
    -moz-box-shadow: none;
    -webkit-box-shadow: none;
    box-shadow: none;
  }

  .markdown-body .progress {
    border: 1px solid #ddd;
  }

  .markdown-body .progress-bar {
    height: 22px;
    border-right: 1px solid #ddd;
  }

  .markdown-body tr,
  .markdown-body img {
    page-break-inside: avoid;
  }

  .markdown-body img {
    max-width: 100% !important;
  }

  .markdown-body p,
  .markdown-body h2,
  .markdown-body h3 {
    orphans: 3;
    widows: 3;
  }

  .markdown-body h2,
  .markdown-body h3 {
    page-break-after: avoid;
  }
}
</style><title>bluedata_ds_pipelines</title></head><body><article class="markdown-body"><p><span style="color:#f2cf4a; font-family: 'Bookman Old Style';"></p>
<h1 id="datascience-pipelines"><a name="user-content-datascience-pipelines" href="#datascience-pipelines" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Datascience-Pipelines</h1>
<ul>
<li><a href="#1-jupyterhub-server-with-spark2.1.1">1. JupyterHub Server with Spark2.1.1</a></li>
<li><a href="#2-nifi-hdf2.1-with-embedded-zookeepers">2. Nifi-HDF2.1 with embedded Zookeepers</a></li>
<li><a href="#3-kafka-spark-and-cassandra-pipeline-in-bluedata">3. Kafka Spark and Cassandra pipeline in BlueData</a></li>
<li><a href="#4-r-studio-server-with-spark-2.1.0">4. R-Studio Server with Spark 2.1.0</a></li>
</ul>
<h2 id="1-jupyterhub-server-with-spark211"><a name="user-content-1-jupyterhub-server-with-spark211" href="#1-jupyterhub-server-with-spark211" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>1. JupyterHub Server with Spark2.1.1</h2>
<p><em>Location</em>: <a href="https://s3.amazonaws.com/bluedata-catalog/solutions/bins/bdcatalog-centos-bluedata-jupyterhubsp-1.2.bin">https://s3.amazonaws.com/bluedata-catalog/solutions/bins/bdcatalog-centos-bluedata-jupyterhubsp-1.2.bin</a></p>
<p><em>DistroId</em>: bluedata/jupyterhubsp</p>
<p><em>Version</em>: 1.2</p>
<p><em>Category</em>: Notebooks</p>
<p><em>Software Included</em>: </p>
<pre><code>  Jupyterhub version - 0.7.2
  Python 3.6.0 |Anaconda 4.3.1 (64-bit)
  Anaconda on Python 3 : conda 4.3.14
  Spark-2.1.1-bin-hadoop2.6, configured to run on Python 3
  Jupyter Toree kernels - Scala, PySpark, SQL (toree-0.2.0.dev1.tar.gz)
</code></pre>
<p><em>Jupyterhub access</em>:</p>
<pre><code> Jupyterhub server  - Create a OS user for each user who needs access on cluster controller node.
 ‘sudo useradd test’
 ‘sudo passwd test’ -&gt; provide password  
 Login with test/password
</code></pre>
<p><em>Systemv Service names and commands</em>:</p>
<pre><code> sudo service jupyterhub status (start, stop)
 sudo service spark-master status (start, stop)
 sudo service spak-slave status (start, stop)
</code></pre>
<p><em>OS</em>: Centos. Works with both Bluedata Centos and RHEL hosts</p>
<p><em>Sample Code for Testing</em>:</p>
<pre><code> 1. Create a linux user on master controller node
 2. Login
</code></pre>
<p><em>Spark Scala testing</em>:</p>
<pre><code> 3. Start a toree scala kernel -&gt; Wait till kernel creates a spark shell. Run following Pearson’s correlation. You can run upto 4 Spark shells with current configurations. If your shell doesn’t start, you may have used up all the cores. Kill unused Kernels to release resources
 Code : Running Pearson’s correlation using mllib

 import org.apache.spark.mllib.linalg._
 import org.apache.spark.mllib.stat.Statistics
 import org.apache.spark.rdd.RDD
 val seriesX: RDD[Double] = sc.parallelize(Array(1, 2, 3, 3, 5))  // a series
 // must have the same number of partitions and cardinality as seriesX
 val seriesY: RDD[Double] = sc.parallelize(Array(11, 22, 33, 33, 555))
 // compute the correlation using Pearson's method. Enter "spearman" for Spearman's method. If  a
 // method is not specified, Pearson's method will be used by default.
 val correlation: Double = Statistics.corr(seriesX, seriesY, "pearson")
 println(s"Correlation is: $correlation")
 val data: RDD[Vector] = sc.parallelize(
  Seq(
    Vectors.dense(1.0, 10.0, 100.0),
    Vectors.dense(2.0, 20.0, 200.0),
    Vectors.dense(5.0, 33.0, 366.0))
    )  // note that each Vector is a row and not a column
    // calculate the correlation matrix using Pearson's method. Use "spearman" for Spearman's method
    // If a method is not specified, Pearson's method will be used by default.
    val correlMatrix: Matrix = Statistics.corr(data, "pearson")
    println(correlMatrix.toString)
</code></pre>
<p><em>Input</em>:  Input is generated within the code. No external input is provided.</p>
<p><em>Output</em>: Sample output is as given below.</p>
<pre><code> ![jupyter](images/jupyter.jpg)
</code></pre>
<p><em>PySpark testing</em>:</p>
<pre><code> 4. Start a toree pySpark kernel -&gt; Wait till kernel creates a spark shell. You can run upto 4 Spark shells with current configurations. If your shell doesn’t start, you may have used up all the cores. Kill unused Kernels to release resources.
 Code: 
 from pyspark import SparkConf, SparkContext
 from sklearn.datasets import make_classification
 from sklearn.ensemble import ExtraTreesClassifier
 import pandas as pd
 import numpy as np
 # Build a classification task using 3 informative features
 X, y = make_classification(n_samples=12000,
                    n_features=10,
                    n_informative=3,
                    n_redundant=0,
                    n_repeated=0,
                    n_classes=2,
                    random_state=0,
                    shuffle=False)
# Partition data
def dataPart(X, y, start, stop): return dict(X=X[start:stop, :], y=y[start:stop])
def train(data):
    X = data['X']
    y = data['y']
    return ExtraTreesClassifier(n_estimators=100,random_state=0).fit(X,y)
# Merge 2 Models
from sklearn.base import copy
def merge(left,right):
    new = copy.deepcopy(left)
    new.estimators_ += right.estimators_
    new.n_estimators = len(new.estimators_) 
    return new
data = [dataPart(X, y, 0, 4000), dataPart(X,y,4000,8000),dataPart(X,y,8000,12000)]
forest = sc.parallelize(data).map(train).reduce(merge)
importances = forest.feature_importances_
std = np.std([tree.feature_importances_ for tree in forest.estimators_],
      axis=0)
indices = np.argsort(importances)[::-1]
# Print the feature ranking
print("Feature ranking:")
for f in range(10):
        print("%d. feature %d (%f)" % (f + 1, indices[f], importances[indices[f]]))
</code></pre>
<p><em>Input</em>: No input files used. Data is generated in the code. </p>
<p><em>Output</em>: Sample output is as given below.</p>
<pre><code>  ![pyspark](images/pyspark.jpg)
</code></pre>
<h2 id="2-nifi-hdf21-with-embedded-zookeepers"><a name="user-content-2-nifi-hdf21-with-embedded-zookeepers" href="#2-nifi-hdf21-with-embedded-zookeepers" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>2. Nifi-HDF2.1 with embedded Zookeepers</h2>
<p><em>Location</em>: <a href="https://s3.amazonaws.com/bluedata-catalog/solutions/bins/bdcatalog-centos-bluedata-hdf21base-3.0.bin">https://s3.amazonaws.com/bluedata-catalog/solutions/bins/bdcatalog-centos-bluedata-hdf21base-3.0.bin</a></p>
<p><em>DistroId</em>: bluedata/hdf21base</p>
<p><em>Version</em>: 3.0</p>
<p><em>Category</em>: ETLTools</p>
<p><em>Software Included</em>: </p>
<pre><code>  java version "1.8.0_40"
  nifi-1.1.0.2.1.2.0-10-bin.tar.gz
  zookeeper-3.4.6.tar.gz
</code></pre>
<p><em>Notebook access</em>:</p>
<pre><code> Nifi UI (open to everyone, once deployed)
</code></pre>
<p><em>Systemv Service names and commands</em>:</p>
<pre><code> sudo service HDF-master status (stop, start)
 sudo service HDF-slave status(stop, start)
 sudo service Zookeeper-service status (start, stop)
</code></pre>
<p><em>OS</em>: Centos6. Works on both Centos and RHEL base machines</p>
<p><em>Sample workflow for Testing</em>:</p>
<pre><code> 1. Let us build a small flow on NiFi canvas to read app log generated by NiFi itself to feed to Spark:
 2. Drop a "TailFile" Processor to canvas to read lines added to"/opt/HDF-2.1.1/nifi-1.1.0.2.1.1.0-2/logs/nifi-app.log". Auto Terminate relationship Failure.


  ![TailFile-1](images/TailFile-1.png)

 3. Drop a "SplitText" Processor to canvas to split the log file into separate lines. Auto terminate Original and Failure Relationship for now. Connect TailFile processor to SplitText Processor for Success Relationship.


 ![SplitText-2](images/SplitText-2.png)

 4. Drop a "ExtractText" Processor to canvas to extract portions of the log content to attributes as below. Connect SplitText processor to ExtractText Processor for splits relationship.
    - BULLETIN_LEVEL:([A-Z]{4,5})
    - CONTENT:(^.*)
    - EVENT_DATE:([^,]*)
    - EVENT_TYPE:(?&lt;=\[)(.*?)(?=\])

 ![ExtractText-3](images/ExtractText-3.png)

 5. Now create a PutFile Processor to store end result in local.

 ![PutFile-4](images/PutFile-4.png)

 6. The final workflow looks like the image below.

 ![Workflow-5](images/Workflow-5.png)
</code></pre>
<p><em>Output</em>: Sample output is as given below. </p>
<pre><code> ![output-6](images/output-6.png)
</code></pre>
<h2 id="3kafka-spark-and-cassandra-pipeline-in-bluedata"><a name="user-content-3kafka-spark-and-cassandra-pipeline-in-bluedata" href="#3kafka-spark-and-cassandra-pipeline-in-bluedata" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>3.Kafka Spark and Cassandra pipeline in BlueData</h2>
<p><em>Location</em>: </p>
<p><em>DistroId</em>: </p>
<p><em>Version</em>: </p>
<p><em>Category</em>: Notebooks</p>
<p><em>Software Included</em>: </p>
<p><em>Sample code for Testing</em>: </p>
<p><em>Description</em>:</p>
<pre><code>The sample program is designed to do the following:
    1.Generate “consumer complaints” topics generated periodically from a file downloaded from data.gov, into a Kafka queue called “consumer_complaints”

    2.Spark cluster will read these complaints and process them on an on-going basis
    3.Processed complaints are then stored in Cassandra for iterative and further use.
</code></pre>
<p><em>Generate Kafka events</em>:</p>
<pre><code>   1.Log into Kafka cluster command line using “ssh -i “Tenant Keypair” bluedata@kafka-node-ip
   2.Create a new “src” directory. CD to src
   3.Setup the environment for running applications
            a.Install Maven to build the sample code using standard Maven documentation. Sample installation from http://preilly.me/2013/05/10/how-to-install-maven-on-centos/
                    i) $ wget http://mirror.cc.columbia.edu/pub/software/apache/maven/maven-3/3.0.5/binaries/apache-maven-3.0.5-bin.tar.gz
                    ii) $ sudo tar xzf apache-maven-3.0.5-bin.tar.gz -C /usr/local
                    iii) $ cd /usr/local
                    iv) $ sudo ln -s apache-maven-3.0.5 maven
                    v) $ sudo vi /etc/profile.d/maven.sh
                            export M2_HOME=/usr/local/maven
                            export PATH=${M2_HOME}/bin:${PATH}
            b.Exit and re-login. cd to src.
            c.Run “mvn -version” and validate maven home and java home variables
    4.If you don’t have git installed, run “sudo yum install git”
    5.git clone https://github.com/nandav/Realtime-Pipeline.git
    6.cd to “Realtime-Pipeline”
    7.tar -xvzf Consumer.tgz -C ./file-producer/
    8.cd to “file-producer”
    9.Edit  “src/main/resources/config.properties”. Update the hostname “bluedata-175.bdlocal” with your kafka hostname
    10.Run the command “mvn clean install”. If all goes well you should see success when this command finishes running. 
    11.Create a kafka topic called “consumer_complains” by running the following command. Be sure to change the &lt;hostname&gt; with the name of your kafka machine.
        /usr/local/kafka_2.10-0.8.2.2/bin/kafka-topics.sh --create  --zookeeper &lt;hostname&gt;:2181 --replication-factor 1 --partition 1 --topic consumer_complaints
    12.Run the command “java -cp target/kafkamessages-0.0.1-SNAPSHOT.jar com.bluedata.messages.TestProducer 10”
    13.You should see producer creating messages
    14.&lt;ctrl&gt; c (kill process )now to stop the messages at this point.
</code></pre>
<p><em>Consume Kafka events and add data to a Cassandra table using Spark streaming</em>:</p>
<pre><code>  1.Login to Spark cluster master using “ssh -i “Tenant KeyPair” bluedata@spark-master-ip
  2.Create a directory src.  “mkdir src”. Then “cd src”
  3.You need sbt to build the source code. Install sbt using standard sbt documentation. A sample installation is given here. Following this should also work

  wget http://dl.bintray.com/sbt/rpm/sbt-0.13.5.rpm
  sudo yum localinstall sbt-0.13.5.rpm

  4.Install git to clone “Spark consumer” for consumer complaints. &lt;sudo yum install git&gt;
  5.git clone https://github.com/nandav/Realtime-Pipeline.git
  6.cd into “Realtime-Pipeline”
  7.cd into “spark_consumer”
  8.Edit “consumer.conf” file. Modify “spark.master”,  “spark.kafka.broker”, and “spark.cassandra.connection.host” to point to  the right hosts. spark master should be the hostname of spark master. Kafka broker to point to first node of kafka cluster. Similarly, update Cassandra connection host to the ip address of Cassandra first node. 
  9.Run “sbt assembly”. Runs for sometime and downloads all the dependencies for Kafka and Cassandra from Spark. 
  10.Run “sudo bash” to login as root to the container. There are some log files that need “root” permission. 
  11.If you like less verbose logs from Spark, edit the following file and update INFO to ERROR as shown below. 
        a.vi /usr/lib/spark/spark-1.4.0-bin-hadoop2.4/conf/log4j.properties  (If you have a different version of Spark, be sure to replace 1.4 with your version of Spark in “build.sbt”). Cassandra connector is 1.5.0 of Spark
        b.Update line “log4j.rootLogger=” from INFO to ERROR
        c.Modified line looks like “log4j.rootLogger=ERROR, file, stdout ,stderr”
  12.Run the following command. Be sure to update &lt;SparkMaster&gt; with actual Spark Master hostname.  spark-submit --properties-file consumer.conf --class KafkaSparkCassandra --master spark://&lt;SparkMaster&gt;:7077 target/scala-2.10/kafka-streaming-cassandra-assembly-1.0.jar
</code></pre>
<p><em>Check updates on Cassandra cluster</em>:</p>
<pre><code>  3.Login to Cassandra cluster using “ssh -i “Tenant KeyPair” bluedata@&lt;Cassandra_Node&gt;
  4.Run “export CQLSH_HOST=&lt;IP of first cassandra node&gt;”. 
    Example: export CQLSH_HOST=10.39.249.18
  5.Run “cqlsh”
  6.Type command “describe keyspaces;”. You should see ‘bluedata’ as one of the key spaces. 
  7.Type “use bluedata;”
  8.Type “describe tables;”. You should see a table called ‘consumer_complaints’
  9.Type “select count(*) from consumer_complaints;”. Counts should keep increasing. 
  10.Type “Select * from consumer_complaints;”.
</code></pre>
<p><em>Summary</em>:</p>
<pre><code>   At the end of this workflow, you should see that Kafka is reading a file, creating messages into Kafka queue. Spark streaming is processing it and storing it in Cassandra. This is a powerful workflow that can be altered to suit your needs.
</code></pre>
<p><em>Running sample 2</em>:</p>
<p><em>Description</em>:</p>
<pre><code>  The sample program is designed to do the following:
    1.Collect tweets into a Kafka queue called “twitter-topic”
    2.Spark cluster will read these tweets and process popular hashtags in last 60 seconds, on a continuous basis
</code></pre>
<p><em>Generate Kafka events</em>:</p>
<pre><code>  1.Log into Kafka cluster command line using “ssh -i “Tenant Keypair” bluedata@kafka-node-ip
  2.Create a new “src” directory. CD to src
  3.Setup the environment for running applications
        a.Install Maven to build the sample code using standard Maven documentation. Sample installation from http://preilly.me/2013/05/10/how-to-install-maven-on-centos/
                i. $ wget http://mirror.cc.columbia.edu/pub/software/apache/maven/maven-3/3.0.5/binaries/apache-maven-3.0.5-bin.tar.gz
                ii. $ sudo tar xzf apache-maven-3.0.5-bin.tar.gz -C /usr/local
                iii. $ cd /usr/local
                iv. $ sudo ln -s apache-maven-3.0.5 maven
                v.$ sudo vi /etc/profile.d/maven.sh
                        export M2_HOME=/usr/local/maven
                        export PATH=${M2_HOME}/bin:${PATH}
        b.Exit and log back into the shell
        c.Run mvn -version and validate maven home and java home variables
  4.If you don’t have git installed, run “sudo yum install git”
  5.git clone https://github.com/nandav/twitter-producer.git
  6.cd to “twitter-producer”
  7.Edit  “config.properties”. Update the hostname  with your kafka hostname and change all twitter access credentials to your credentials. If you do not have twitter app credentials, please login to apps.twitter.com-&gt;Create New App following directions. You should be able to obtain all 4 credentials. 
  8.Run the command “mvn clean install”. If all goes well you should see success when this command finishes running. 
  9.Create a kafka topic called “twitter-topic” by running the following command. Please make sure to change &lt;hostname&gt; to appropriate name, It is the first node of Kafka cluster where zookeeper is installed. Mostly your current logged in machine. “/usr/local/kafka_2.10-0.8.2.2/bin/kafka-topics.sh --create  --zookeeper &lt;hostname&gt;:2181 --replication-factor 1 --partition 1 --topic twitter-topic”
  10.Start twitter producer using the following command “java -cp target/kafkamessages-0.0.1-SNAPSHOT.jar com.bluedata.messages.TwitterKafkaProducer”
  11.Open a new shell window and start a kafka console consumer.  Be sure to change name of kafka-first-name before running the command. /usr/local/kafka_2.10-0.8.2.2/bin/kafka-console-consumer.sh --zookeeper &lt;kafka-first-node&gt;:2181 --topic twitter-topic
</code></pre>
<p><em>Consume Kafka events using Spark streaming</em>:</p>
<pre><code>  1.Login to Spark cluster master using “ssh -i “Tenant KeyPair” bluedata@spark-master-ip
  2.Create a directory src.  “mkdir src”. Then “cd src”
  3.You need sbt to build the source code. Install sbt using standard sbt documentation. A sample installation is given here. Following this should also work
  4.wget http://dl.bintray.com/sbt/rpm/sbt-0.13.5.rpm
  5.sudo yum localinstall sbt-0.13.5.rpm
  6.Install git to clone “Spark consumer” for Kafka tweets. &lt;sudo yum install git&gt;
  7.git clone https://github.com/nandav/twitter-spark-consumer.git
  8.cd into “twitter-spark-consumer/
  9.Edit “consumer.conf” file. Modify “spark.master”,  “spark.kafka.broker”, to point to  the right hosts. spark master should be the hostname of spark master. Kafka broker to point to first node of kafka cluster.
  10.Run “sbt assembly”. Runs for sometime and downloads all the dependencies for Kafka and Spark Streaming. (If you have a different version of Spark, be sure to replace 1.4 with your version of Spark in “build.sbt”)
  11.Run “sudo bash” to login as root to the container. There are some files that need “root” permission. 
  12.If you like less verbose logs from Spark, edit the following file and update INFO to ERROR as shown below. 
            a.vi /usr/lib/spark/spark-1.4.0-bin-hadoop2.4/conf/log4j.properties (Or modify the spark directory to reflect your cluster)
            b.Update line “log4j.rootLogger=” from INFO to ERROR
            c.Modified line looks like “log4j.rootLogger=ERROR, file, stdout ,stderr”
  13.Run the following command “spark-submit --properties-file consumer.conf --class KafkaSparkStreaming --master spark://&lt;Spark-master&gt;:7077 target/scala-2.10/kafka-streaming-assembly-1.0.jar”
  14.You should see popular hashtags in last 60 seconds in rolling fashion 
  15.End producer and consumer  using &lt;ctrl&gt; c - kill the process
</code></pre>
<p>## 4. R-Studio Server with Spark 2.1.0</p>
<p><em>Location</em>: <a href="https://s3.amazonaws.com/bluedata-catalog/solutions/bins/bdcatalog-centos-bluedata-jupyterhubsp-1.2.bin">https://s3.amazonaws.com/bluedata-catalog/solutions/bins/bdcatalog-centos-bluedata-jupyterhubsp-1.2.bin</a></p>
<p><em>DistroId</em>: bluedata/jupyterhubsp</p>
<p><em>Version</em>: 1.2</p>
<p><em>Category</em>: Notebooks</p>
<p><em>Software Included</em>: </p>
<pre><code>  Jupyterhub version - 0.7.2
  Python 3.6.0 |Anaconda 4.3.1 (64-bit)
  Anaconda on Python 3 : conda 4.3.14
  Spark-2.1.1-bin-hadoop2.6, configured to run on Python 3
  Jupyter Toree kernels - Scala, PySpark, SQL (toree-0.2.0.dev1.tar.gz)
</code></pre>
<p><em>Jupyterhub access</em>:</p>
<pre><code> Jupyterhub server  - Create a OS user for each user who needs access on cluster controller node.
 ‘sudo useradd test’
 ‘sudo passwd test’ -&gt; provide password  
 Login with test/password
</code></pre>
<p><em>Systemv Service names and commands</em>:</p>
<pre><code> sudo service jupyterhub status (start, stop)
 sudo service spark-master status (start, stop)
 sudo service spak-slave status (start, stop)
</code></pre>
<p><em>OS</em>: Centos. Works with both Bluedata Centos and RHEL hosts</p>
<p><em>Sample Code for Testing</em>:</p>
<pre><code> 1. Create a linux user on master controller node
 2. Login
</code></pre>
<p><em>Spark Scala testing</em>:</p>
<pre><code> 3. Start a toree scala kernel -&gt; Wait till kernel creates a spark shell. Run following Pearson’s correlation. You can run upto 4 Spark shells with current configurations. If your shell doesn’t start, you may have used up all the cores. Kill unused Kernels to release resources
 Code : Running Pearson’s correlation using mllib

 import org.apache.spark.mllib.linalg._
 import org.apache.spark.mllib.stat.Statistics
 import org.apache.spark.rdd.RDD
 val seriesX: RDD[Double] = sc.parallelize(Array(1, 2, 3, 3, 5))  // a series
 // must have the same number of partitions and cardinality as seriesX
 val seriesY: RDD[Double] = sc.parallelize(Array(11, 22, 33, 33, 555))
 // compute the correlation using Pearson's method. Enter "spearman" for Spearman's method. If  a
 // method is not specified, Pearson's method will be used by default.
 val correlation: Double = Statistics.corr(seriesX, seriesY, "pearson")
 println(s"Correlation is: $correlation")
 val data: RDD[Vector] = sc.parallelize(
  Seq(
    Vectors.dense(1.0, 10.0, 100.0),
    Vectors.dense(2.0, 20.0, 200.0),
    Vectors.dense(5.0, 33.0, 366.0))
    )  // note that each Vector is a row and not a column
    // calculate the correlation matrix using Pearson's method. Use "spearman" for Spearman's method
    // If a method is not specified, Pearson's method will be used by default.
    val correlMatrix: Matrix = Statistics.corr(data, "pearson")
    println(correlMatrix.toString)
</code></pre>
<p><em>Input</em>:  Input is generated within the code. No external input is provided.</p>
<p><em>Output</em>: Sample output is as given below.</p></article></body></html>