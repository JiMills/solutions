{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's say we want multiple processes to have shared access to some common parameters. \n",
    "#For simplicity, suppose this is just a single variable:\n",
    "var = tf.Variable(initial_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#As a first step, we can imagine that each process would need its own session. \n",
    "#(Pretend session 1 is created in one process, and session 2 in another.)\n",
    "\n",
    "sess1 = tf.Session()\n",
    "sess2 = tf.Session()\n",
    "\n",
    "sess1.run(tf.global_variables_initializer())\n",
    "sess2.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Initial value of var in session 1:', 0.0)\n",
      "('Initial value of var in session 2:', 0.0)\n",
      "Incremented var in session 1\n",
      "('Value of var in session 1:', 1.0)\n",
      "('Value of var in session 2:', 0.0)\n"
     ]
    }
   ],
   "source": [
    "#Each call to tf.Session() creates a separate execution engine, then connects the session handle to the execution engine. \n",
    "#The execution engine is what actually stores variable values and runs operations.\n",
    "#Normally, execution engines in different processes are unlinked. \n",
    "#Changing var in one session (on one execution engine) won't affect var in the other session.\n",
    "\n",
    "print(\"Initial value of var in session 1:\", sess1.run(var))\n",
    "print(\"Initial value of var in session 2:\", sess2.run(var))\n",
    "\n",
    "sess1.run(var.assign_add(1.0))\n",
    "print(\"Incremented var in session 1\")\n",
    "\n",
    "print(\"Value of var in session 1:\", sess1.run(var))\n",
    "print(\"Value of var in session 2:\", sess2.run(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In order to share variables between processes, we need to link the different execution engines together. Enter Distributed TensorFlow.\n",
    "\n",
    "#With Distributed TensorFlow, each process runs a special execution engine: a TensorFlow server. \n",
    "#Servers are linked together as part of a cluster. (Each server in the cluster is also known as a task.)\n",
    "\n",
    "#The first step is to define what the cluster looks like. We start off with the simplest possible cluster: two servers (two tasks), both on the same machine; \n",
    "#one that will listen on port 2222, one on port 2223.\n",
    "\n",
    "tasks = [\"localhost:2222\", \"localhost:2223\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Each task is associated with a job, which is a collection of related tasks. \n",
    "#We associate both tasks with a job called \"local\".#\n",
    "\n",
    "jobs = {\"local\": tasks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This completes the definition of the cluster.\n",
    "\n",
    "cluster = tf.train.ClusterSpec(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We can now launch the servers, specifying which server in the cluster definition each server corresponds to. \n",
    "#Each server starts immediately, listening on the port specified in the cluster definition.\n",
    "\n",
    "# \"This server corresponds to the the first task (task_index=0)\n",
    "# of the tasks associated with the 'local' job.\"\n",
    "server1 = tf.train.Server(cluster, job_name=\"local\", task_index=0)\n",
    "\n",
    "server2 = tf.train.Server(cluster, job_name=\"local\", task_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#With the servers linked together in the same cluster, we can now experience the main magic of Distributed TensorFlow: \n",
    "#any variable with the same name will be shared between all servers.\n",
    "#The simplest example is to run the same graph on all servers, each graph with just one variable, as before:\n",
    "\n",
    "tf.reset_default_graph()\n",
    "var = tf.Variable(initial_value=0.0, name='var')\n",
    "sess1 = tf.Session(server1.target)\n",
    "sess2 = tf.Session(server2.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Initial value of var in session 1:', 0.0)\n",
      "('Initial value of var in session 2:', 0.0)\n",
      "Incremented var in session 1\n",
      "('Value of var in session 1:', 1.0)\n",
      "('Value of var in session 2:', 1.0)\n"
     ]
    }
   ],
   "source": [
    "#Modifications made to the variable on one server will now be mirrored on the second server.\n",
    "\n",
    "sess1.run(tf.global_variables_initializer())\n",
    "sess2.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"Initial value of var in session 1:\", sess1.run(var))\n",
    "print(\"Initial value of var in session 2:\", sess2.run(var))\n",
    "\n",
    "sess1.run(var.assign_add(1.0))\n",
    "print(\"Incremented var in session 1\")\n",
    "\n",
    "print(\"Value of var in session 1:\", sess1.run(var))\n",
    "print(\"Value of var in session 2:\", sess2.run(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Placement\n",
    "#A question that might be in our minds at this point is: which server does the variable actually get stored on? \n",
    "#And for operations, which server actually runs them?\n",
    "#Empirically, it seems that by default, variables and operations get placed on the first task in the cluster.\n",
    "\n",
    "def run_with_location_trace(sess, op):\n",
    "    # From https://stackoverflow.com/a/41525764/7832197\n",
    "    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "    run_metadata = tf.RunMetadata()\n",
    "    sess.run(op, options=run_options, run_metadata=run_metadata)\n",
    "    for device in run_metadata.step_stats.dev_stats:\n",
    "      print(device.device)\n",
    "      for node in device.node_stats:\n",
    "        print(\"  \", node.node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:local/replica:0/task:0/device:CPU:0\n",
      "('  ', u'_SOURCE')\n",
      "('  ', u'var')\n"
     ]
    }
   ],
   "source": [
    "#For example, if we do something to var using the session connected to the first task, everything happens on that task:\n",
    "\n",
    "run_with_location_trace(sess1, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:local/replica:0/task:0/device:CPU:0\n",
      "('  ', u'_SOURCE')\n",
      "('  ', u'AssignAdd_1/value')\n",
      "('  ', u'var')\n",
      "('  ', u'AssignAdd_1')\n"
     ]
    }
   ],
   "source": [
    "run_with_location_trace(sess1, var.assign_add(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:local/replica:0/task:1/device:CPU:0\n",
      "('  ', u'RecvTensor')\n",
      "/job:local/replica:0/task:1/device:CPU:0\n",
      "('  ', u'_SOURCE')\n",
      "/job:local/replica:0/task:0/device:CPU:0\n",
      "('  ', u'_SOURCE')\n",
      "('  ', u'var')\n"
     ]
    }
   ],
   "source": [
    "#But if we try and try do something to var using the session connected to the second task, \n",
    "#the graph nodes still get run on the first task\n",
    "\n",
    "run_with_location_trace(sess2, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To fix a variable or an operation to a specific task, we can use tf.device:\n",
    "\n",
    "with tf.device(\"/job:local/task:0\"):\n",
    "    var1 = tf.Variable(0.0, name='var1')\n",
    "with tf.device(\"/job:local/task:1\"):\n",
    "    var2 = tf.Variable(0.0, name='var2')\n",
    "    \n",
    "# (This will initialize both variables)\n",
    "sess1.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:local/replica:0/task:0/device:CPU:0\n",
      "('  ', u'_SOURCE')\n",
      "('  ', u'var1')\n"
     ]
    }
   ],
   "source": [
    "#Now var1 runs on the first task, as before.\n",
    "\n",
    "run_with_location_trace(sess1, var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:local/replica:0/task:0/device:CPU:0\n",
      "('  ', u'RecvTensor')\n",
      "/job:local/replica:0/task:0/device:CPU:0\n",
      "('  ', u'_SOURCE')\n",
      "/job:local/replica:0/task:1/device:CPU:0\n",
      "('  ', u'_SOURCE')\n",
      "('  ', u'var2')\n"
     ]
    }
   ],
   "source": [
    "#But var2 runs on the second task. Even if we try to evaluate it using the session connected to the first task, \n",
    "#it still runs on the second task.\n",
    "\n",
    "run_with_location_trace(sess1, var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:local/replica:0/task:1/device:CPU:0\n",
      "('  ', u'_SOURCE')\n",
      "('  ', u'var2')\n"
     ]
    }
   ],
   "source": [
    "#And vice-versa with var2.\n",
    "\n",
    "run_with_location_trace(sess2, var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:local/replica:0/task:1/device:CPU:0\n",
      "('  ', u'RecvTensor')\n",
      "/job:local/replica:0/task:1/device:CPU:0\n",
      "('  ', u'_SOURCE')\n",
      "/job:local/replica:0/task:0/device:CPU:0\n",
      "('  ', u'_SOURCE')\n",
      "('  ', u'var1')\n"
     ]
    }
   ],
   "source": [
    "run_with_location_trace(sess2, var1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
